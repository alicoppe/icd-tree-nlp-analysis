{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from bert_wrapper import BERTWrapper\n",
    "from scripts.probe import TwoWordPSDProbe\n",
    "from scripts.probe_regimen import ProbeRegimen\n",
    "from scripts.loss import L1DistanceLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricting the analysis to the selectable ICD-10 codes, meaning those that would actually be used in practice. The non-selectable codes represent broader categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coding</th>\n",
       "      <th>meaning</th>\n",
       "      <th>node_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>selectable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000</td>\n",
       "      <td>A00.0 Cholera due to Vibrio cholerae 01, biova...</td>\n",
       "      <td>287</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A001</td>\n",
       "      <td>A00.1 Cholera due to Vibrio cholerae 01, biova...</td>\n",
       "      <td>288</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A009</td>\n",
       "      <td>A00.9 Cholera, unspecified</td>\n",
       "      <td>289</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A010</td>\n",
       "      <td>A01.0 Typhoid fever</td>\n",
       "      <td>291</td>\n",
       "      <td>290.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A011</td>\n",
       "      <td>A01.1 Paratyphoid fever A</td>\n",
       "      <td>292</td>\n",
       "      <td>290.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150</th>\n",
       "      <td>Z992</td>\n",
       "      <td>Z99.2 Dependence on renal dialysis</td>\n",
       "      <td>19150</td>\n",
       "      <td>19147.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19151</th>\n",
       "      <td>Z993</td>\n",
       "      <td>Z99.3 Dependence on wheelchair</td>\n",
       "      <td>19151</td>\n",
       "      <td>19147.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19152</th>\n",
       "      <td>Z994</td>\n",
       "      <td>Z99.4 Dependence on artificial heart</td>\n",
       "      <td>19152</td>\n",
       "      <td>19147.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>Z998</td>\n",
       "      <td>Z99.8 Dependence on other enabling machines an...</td>\n",
       "      <td>19153</td>\n",
       "      <td>19147.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>Z999</td>\n",
       "      <td>Z99.9 Dependence on unspecified enabling machi...</td>\n",
       "      <td>19154</td>\n",
       "      <td>19147.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16310 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coding                                            meaning  node_id  \\\n",
       "4       A000  A00.0 Cholera due to Vibrio cholerae 01, biova...      287   \n",
       "5       A001  A00.1 Cholera due to Vibrio cholerae 01, biova...      288   \n",
       "6       A009                         A00.9 Cholera, unspecified      289   \n",
       "8       A010                                A01.0 Typhoid fever      291   \n",
       "9       A011                          A01.1 Paratyphoid fever A      292   \n",
       "...      ...                                                ...      ...   \n",
       "19150   Z992                 Z99.2 Dependence on renal dialysis    19150   \n",
       "19151   Z993                     Z99.3 Dependence on wheelchair    19151   \n",
       "19152   Z994               Z99.4 Dependence on artificial heart    19152   \n",
       "19153   Z998  Z99.8 Dependence on other enabling machines an...    19153   \n",
       "19154   Z999  Z99.9 Dependence on unspecified enabling machi...    19154   \n",
       "\n",
       "       parent_id selectable  \n",
       "4          286.0          Y  \n",
       "5          286.0          Y  \n",
       "6          286.0          Y  \n",
       "8          290.0          Y  \n",
       "9          290.0          Y  \n",
       "...          ...        ...  \n",
       "19150    19147.0          Y  \n",
       "19151    19147.0          Y  \n",
       "19152    19147.0          Y  \n",
       "19153    19147.0          Y  \n",
       "19154    19147.0          Y  \n",
       "\n",
       "[16310 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ICD10.csv')\n",
    "\n",
    "\n",
    "df_codes = df[df['selectable'] == 'Y']\n",
    "icd_codes = df_codes['coding'].tolist()\n",
    "df_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/8z_2wkxn7hx2ytzbzxsgwdjm0000gn/T/ipykernel_57206/2651920677.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_codes.loc[:, 'text'] = df_codes.apply(\n"
     ]
    }
   ],
   "source": [
    "df_codes.loc[:, 'text'] = df_codes.apply(\n",
    "    lambda row: row['meaning'][row['meaning'][:10].rfind(row['coding'][-1])+2:] \n",
    "    if row['coding'][-1] in row['meaning'][:10] else row['meaning'], \n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coding</th>\n",
       "      <th>text</th>\n",
       "      <th>node_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
       "      <td>287</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A001</td>\n",
       "      <td>Cholera due to Vibrio cholerae 01, biovar el tor</td>\n",
       "      <td>288</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A009</td>\n",
       "      <td>Cholera, unspecified</td>\n",
       "      <td>289</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A010</td>\n",
       "      <td>Typhoid fever</td>\n",
       "      <td>291</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A011</td>\n",
       "      <td>Paratyphoid fever A</td>\n",
       "      <td>292</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150</th>\n",
       "      <td>Z992</td>\n",
       "      <td>Dependence on renal dialysis</td>\n",
       "      <td>19150</td>\n",
       "      <td>19147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19151</th>\n",
       "      <td>Z993</td>\n",
       "      <td>Dependence on wheelchair</td>\n",
       "      <td>19151</td>\n",
       "      <td>19147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19152</th>\n",
       "      <td>Z994</td>\n",
       "      <td>Dependence on artificial heart</td>\n",
       "      <td>19152</td>\n",
       "      <td>19147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>Z998</td>\n",
       "      <td>Dependence on other enabling machines and devices</td>\n",
       "      <td>19153</td>\n",
       "      <td>19147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>Z999</td>\n",
       "      <td>Dependence on unspecified enabling machine and...</td>\n",
       "      <td>19154</td>\n",
       "      <td>19147.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16310 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      coding                                               text  node_id  \\\n",
       "4       A000  Cholera due to Vibrio cholerae 01, biovar chol...      287   \n",
       "5       A001   Cholera due to Vibrio cholerae 01, biovar el tor      288   \n",
       "6       A009                               Cholera, unspecified      289   \n",
       "8       A010                                      Typhoid fever      291   \n",
       "9       A011                                Paratyphoid fever A      292   \n",
       "...      ...                                                ...      ...   \n",
       "19150   Z992                       Dependence on renal dialysis    19150   \n",
       "19151   Z993                           Dependence on wheelchair    19151   \n",
       "19152   Z994                     Dependence on artificial heart    19152   \n",
       "19153   Z998  Dependence on other enabling machines and devices    19153   \n",
       "19154   Z999  Dependence on unspecified enabling machine and...    19154   \n",
       "\n",
       "       parent_id  \n",
       "4          286.0  \n",
       "5          286.0  \n",
       "6          286.0  \n",
       "8          290.0  \n",
       "9          290.0  \n",
       "...          ...  \n",
       "19150    19147.0  \n",
       "19151    19147.0  \n",
       "19152    19147.0  \n",
       "19153    19147.0  \n",
       "19154    19147.0  \n",
       "\n",
       "[16310 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes = df_codes[['coding', 'text', 'node_id', 'parent_id']]\n",
    "df_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text embedding of the ICD code names (*SKIP IF YOU'VE ALREADY DONE THIS*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidanlicoppe/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_BERT = BERTWrapper(model_type=\"bert-base-uncased\", random_init=False)\n",
    "clinical_BERT = BERTWrapper(model_type=\"emilyalsentzer/Bio_ClinicalBERT\", random_init=False)\n",
    "random_BERT = BERTWrapper(random_init=True)\n",
    "\n",
    "base_BERT_embeddings = base_BERT.embed_text_array(df_codes['text'].tolist())\n",
    "clinical_BERT_embeddings = clinical_BERT.embed_text_array(df_codes['text'].tolist())\n",
    "random_BERT_embeddings = random_BERT.embed_text_array(df_codes['text'].tolist())\n",
    "\n",
    "base_BERT_dict = {code: base_BERT_embeddings[i] for i, code in enumerate(icd_codes)}\n",
    "clinical_BERT_dict = {code: clinical_BERT_embeddings[i] for i, code in enumerate(icd_codes)}\n",
    "random_BERT_dict = {code: random_BERT_embeddings[i] for i, code in enumerate(icd_codes)}\n",
    "\n",
    "# Save each dictionary to its own file\n",
    "with open(\"base_BERT_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(base_BERT_dict, file)\n",
    "\n",
    "with open(\"clinical_BERT_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(clinical_BERT_dict, file)\n",
    "\n",
    "with open(\"random_BERT_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(random_BERT_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each dictionary\n",
    "with open(\"base_BERT_dict.pkl\", \"rb\") as file:\n",
    "    base_BERT_dict = pickle.load(file)\n",
    "\n",
    "with open(\"clinical_BERT_dict.pkl\", \"rb\") as file:\n",
    "    clinical_BERT_dict = pickle.load(file)\n",
    "\n",
    "with open(\"random_BERT_dict.pkl\", \"rb\") as file:\n",
    "    random_BERT_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"ICD10.csv\"\n",
    "df_tree = pd.read_csv(file_path, header=0)\n",
    "icd_tree = ICDTree(df_tree)\n",
    "\n",
    "\n",
    "df_codes = df_tree[df_tree['selectable'] == 'Y']\n",
    "icd_codes = df_codes['coding'].tolist()\n",
    "\n",
    "icd_tree = ICDTree(df_tree)\n",
    "\n",
    "icd_codes = locally_shuffle(icd_codes, 100)\n",
    "\n",
    "# Create held out test set \n",
    "icd_codes_train = icd_codes[:int(len(icd_codes)*0.8)]\n",
    "icd_codes_test = icd_codes[int(len(icd_codes)*0.8):]\n",
    "\n",
    "# From the remaining set, create the train and dev sets\n",
    "icd_codes_train = icd_codes_train[:int(len(icd_codes_train)*0.8)]\n",
    "icd_codes_dev = icd_codes_train[int(len(icd_codes_train)*0.8):]\n",
    "\n",
    "probe_rank = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probe Training\n",
    "\n",
    "Initialize ICD Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 0] Training:   3%|▎         | 280/10438 [00:04<02:39, 63.82samples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m L1DistanceLoss()\n\u001b[1;32m      5\u001b[0m probe_regimen1 \u001b[38;5;241m=\u001b[39m ProbeRegimen(icd_tree)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mprobe_regimen1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobe1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_codes_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_codes_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_BERT_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 55\u001b[0m, in \u001b[0;36mProbeRegimen.train\u001b[0;34m(self, probe, loss, train_icd_codes, dev_icd_codes, embedding_dict, batch_size, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Prepare batch inputs\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m batch_embeddings, label_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batch_input_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43micd_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dict\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     62\u001b[0m predictions \u001b[38;5;241m=\u001b[39m probe(batch_embeddings)\n",
      "Cell \u001b[0;32mIn[21], line 36\u001b[0m, in \u001b[0;36mcreate_batch_input_and_labels\u001b[0;34m(icd_code_array, icd_tree, embedding_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m             label_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Distance to itself is zero\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m             label_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43micd_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tree_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43micd_code_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_code_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, label_matrix\n",
      "Cell \u001b[0;32mIn[20], line 150\u001b[0m, in \u001b[0;36mICDTree.get_tree_distance\u001b[0;34m(self, icd_code1, icd_code2)\u001b[0m\n\u001b[1;32m    147\u001b[0m node_id2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node_id_from_coding(icd_code2)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Find the lowest common ancestor (LCA)\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m lca \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lca \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 230\u001b[0m, in \u001b[0;36mICDTree.get_lca\u001b[0;34m(self, node_id1, node_id2)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lca\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id1, node_id2):\n\u001b[0;32m--> 230\u001b[0m     ancestors1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_to_ancestor(node_id1, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_root_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    231\u001b[0m     current \u001b[38;5;241m=\u001b[39m node_id2\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[20], line 93\u001b[0m, in \u001b[0;36mICDTree.get_root_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_root_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the root nodes of the tree.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [node \u001b[38;5;28;01mfor\u001b[39;00m node, degree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39min_degree() \u001b[38;5;28;01mif\u001b[39;00m degree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[20], line 93\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_root_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the root nodes of the tree.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [node \u001b[38;5;28;01mfor\u001b[39;00m node, degree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39min_degree() \u001b[38;5;28;01mif\u001b[39;00m degree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probe1 = TwoWordPSDProbe(base_BERT_dict[\"A000\"].shape[0], 64)\n",
    "\n",
    "loss1 = L1DistanceLoss()\n",
    "\n",
    "probe_regimen1 = ProbeRegimen(icd_tree)\n",
    "\n",
    "probe_regimen1.train(probe1, loss1, icd_codes_train, icd_codes_dev, base_BERT_dict, batch_size=10, name=\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[predicting batches]:   0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[predicting batches]: 100%|██████████| 327/327 [00:48<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.4585213634205754\n"
     ]
    }
   ],
   "source": [
    "probe_loaded1 = TwoWordPSDProbe(base_BERT_dict[\"A000\"].shape[0], 64)  # Replace ProbeModel with your actual model class\n",
    "probe_loaded1.load_state_dict(torch.load('saved_models/base_batch_size_10_epoch_9.pt'))\n",
    "probe_loaded1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "probe_regimen = ProbeRegimen(icd_tree)\n",
    "\n",
    "# Generate predictions\n",
    "predictions, labels = probe_regimen1.predict(probe1, icd_codes_test, base_BERT_dict, batch_size=10)\n",
    "\n",
    "correlations, mean_correlations = calculate_spearman_correlations(predictions, labels)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches: 100%|██████████| 327/327 [00:50<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.498880413276541\n"
     ]
    }
   ],
   "source": [
    "mean_correlations = evaluate_full_correlations(icd_tree, base_BERT_dict, icd_codes_test, batch_size=10, shuffle_icd=False)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 0] Training: 100%|██████████| 10438/10438 [02:39<00:00, 65.46samples/s]\n",
      "[epoch 0] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.77samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] Train loss: 1.520573702009245, Dev loss: 1.2910674453922435\n",
      "[epoch 0] New best model saved at: saved_models/clinical_batch_size_10_epoch_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 1] Training: 100%|██████████| 10438/10438 [02:31<00:00, 68.79samples/s]\n",
      "[epoch 1] Validation: 100%|██████████| 2088/2088 [00:31<00:00, 67.33samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Train loss: 1.2414258820686304, Dev loss: 1.1819702227149853\n",
      "[epoch 1] New best model saved at: saved_models/clinical_batch_size_10_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 2] Training: 100%|██████████| 10438/10438 [02:36<00:00, 66.49samples/s]\n",
      "[epoch 2] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.93samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] Train loss: 1.150104395731199, Dev loss: 1.1113553891341652\n",
      "[epoch 2] New best model saved at: saved_models/clinical_batch_size_10_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 3] Training: 100%|██████████| 10438/10438 [02:33<00:00, 67.98samples/s]\n",
      "[epoch 3] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.23samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] Train loss: 1.0763883380026653, Dev loss: 1.0532372186058445\n",
      "[epoch 3] New best model saved at: saved_models/clinical_batch_size_10_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 4] Training: 100%|██████████| 10438/10438 [02:34<00:00, 67.72samples/s]\n",
      "[epoch 4] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 70.86samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] Train loss: 1.0453882981305835, Dev loss: 0.9980160285981649\n",
      "[epoch 4] New best model saved at: saved_models/clinical_batch_size_10_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 5] Training: 100%|██████████| 10438/10438 [02:32<00:00, 68.61samples/s]\n",
      "[epoch 5] Validation: 100%|██████████| 2088/2088 [00:30<00:00, 68.81samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] Train loss: 1.013547432690973, Dev loss: 0.9796607277610085\n",
      "[epoch 5] New best model saved at: saved_models/clinical_batch_size_10_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 6] Training: 100%|██████████| 10438/10438 [02:40<00:00, 65.06samples/s]\n",
      "[epoch 6] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.64samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] Train loss: 0.9859852891315446, Dev loss: 0.9902253205125983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 7] Training: 100%|██████████| 10438/10438 [02:32<00:00, 68.36samples/s]\n",
      "[epoch 7] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.94samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] Train loss: 0.8453703537526258, Dev loss: 0.7689726697771173\n",
      "[epoch 7] New best model saved at: saved_models/clinical_batch_size_10_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 8] Training: 100%|██████████| 10438/10438 [02:33<00:00, 67.90samples/s]\n",
      "[epoch 8] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.00samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] Train loss: 0.7455706996593439, Dev loss: 0.7074550713933826\n",
      "[epoch 8] New best model saved at: saved_models/clinical_batch_size_10_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 9] Training: 100%|██████████| 10438/10438 [02:37<00:00, 66.28samples/s]\n",
      "[epoch 9] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.51samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] Train loss: 0.7054539959149799, Dev loss: 0.6739295970595054\n",
      "[epoch 9] New best model saved at: saved_models/clinical_batch_size_10_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probe2 = TwoWordPSDProbe(clinical_BERT_dict[\"A000\"].shape[0], 64)\n",
    "\n",
    "loss2 = L1DistanceLoss()\n",
    "\n",
    "probe_regimen2 = ProbeRegimen(icd_tree)\n",
    "\n",
    "probe_regimen2.train(probe2, loss2, icd_codes_train, icd_codes_dev, clinical_BERT_dict, batch_size=10, name=\"clinical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[predicting batches]: 100%|██████████| 327/327 [00:46<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.37179386244581386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probe_loaded2 = TwoWordPSDProbe(clinical_BERT_dict[\"A000\"].shape[0], 64)  # Replace ProbeModel with your actual model class\n",
    "probe_loaded2.load_state_dict(torch.load('saved_models/clinical_batch_size_10_epoch_9.pt'))\n",
    "probe_loaded2.eval()  # Set the model to evaluation mode\n",
    "\n",
    "probe_regimen2 = ProbeRegimen(icd_tree)\n",
    "\n",
    "# Generate predictions\n",
    "predictions2, labels2 = probe_regimen2.predict(probe_loaded2, icd_codes_test, clinical_BERT_dict, batch_size=10)\n",
    "\n",
    "correlations2, mean_correlations2 = calculate_spearman_correlations(predictions2, labels2)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches: 100%|██████████| 327/327 [00:49<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.37709607757004865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_correlations = evaluate_full_correlations(icd_tree, clinical_BERT_dict, icd_codes_test, batch_size=10, shuffle_icd=False)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 0] Training: 100%|██████████| 10438/10438 [02:36<00:00, 66.59samples/s]\n",
      "[epoch 0] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.22samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] Train loss: 1.6444519889537401, Dev loss: 1.4210989093096063\n",
      "[epoch 0] New best model saved at: saved_models/random_batch_size_10_epoch_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 1] Training: 100%|██████████| 10438/10438 [02:32<00:00, 68.59samples/s]\n",
      "[epoch 1] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 70.21samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Train loss: 1.4104640818989596, Dev loss: 1.3088650743356731\n",
      "[epoch 1] New best model saved at: saved_models/random_batch_size_10_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 2] Training: 100%|██████████| 10438/10438 [02:32<00:00, 68.38samples/s]\n",
      "[epoch 2] Validation: 100%|██████████| 2088/2088 [00:28<00:00, 72.87samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] Train loss: 1.3340009189428497, Dev loss: 1.2389429191653238\n",
      "[epoch 2] New best model saved at: saved_models/random_batch_size_10_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 3] Training: 100%|██████████| 10438/10438 [02:32<00:00, 68.60samples/s]\n",
      "[epoch 3] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.02samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] Train loss: 1.2781330351628564, Dev loss: 1.2131268516111602\n",
      "[epoch 3] New best model saved at: saved_models/random_batch_size_10_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 4] Training: 100%|██████████| 10438/10438 [02:31<00:00, 68.91samples/s]\n",
      "[epoch 4] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.77samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] Train loss: 1.2419221013841502, Dev loss: 1.1866808565039384\n",
      "[epoch 4] New best model saved at: saved_models/random_batch_size_10_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 5] Training: 100%|██████████| 10438/10438 [02:33<00:00, 68.00samples/s]\n",
      "[epoch 5] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 71.69samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] Train loss: 1.2182571171458196, Dev loss: 1.1483177973322891\n",
      "[epoch 5] New best model saved at: saved_models/random_batch_size_10_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 6] Training: 100%|██████████| 10438/10438 [02:31<00:00, 69.04samples/s]\n",
      "[epoch 6] Validation: 100%|██████████| 2088/2088 [00:29<00:00, 70.80samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] Train loss: 1.2003826585766, Dev loss: 1.1089944497249913\n",
      "[epoch 6] New best model saved at: saved_models/random_batch_size_10_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch 7] Training:  12%|█▏        | 1260/10438 [00:19<02:19, 65.77samples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m loss3 \u001b[38;5;241m=\u001b[39m L1DistanceLoss()\n\u001b[1;32m      5\u001b[0m probe_regimen3 \u001b[38;5;241m=\u001b[39m ProbeRegimen(icd_tree)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mprobe_regimen3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobe3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_codes_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_codes_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_BERT_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 55\u001b[0m, in \u001b[0;36mProbeRegimen.train\u001b[0;34m(self, probe, loss, train_icd_codes, dev_icd_codes, embedding_dict, batch_size, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Prepare batch inputs\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m batch_embeddings, label_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batch_input_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43micd_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dict\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     62\u001b[0m predictions \u001b[38;5;241m=\u001b[39m probe(batch_embeddings)\n",
      "Cell \u001b[0;32mIn[21], line 36\u001b[0m, in \u001b[0;36mcreate_batch_input_and_labels\u001b[0;34m(icd_code_array, icd_tree, embedding_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m             label_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Distance to itself is zero\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m             label_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43micd_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tree_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43micd_code_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micd_code_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, label_matrix\n",
      "Cell \u001b[0;32mIn[20], line 150\u001b[0m, in \u001b[0;36mICDTree.get_tree_distance\u001b[0;34m(self, icd_code1, icd_code2)\u001b[0m\n\u001b[1;32m    147\u001b[0m node_id2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node_id_from_coding(icd_code2)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Find the lowest common ancestor (LCA)\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m lca \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lca \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 230\u001b[0m, in \u001b[0;36mICDTree.get_lca\u001b[0;34m(self, node_id1, node_id2)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lca\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id1, node_id2):\n\u001b[0;32m--> 230\u001b[0m     ancestors1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_to_ancestor(node_id1, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_root_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    231\u001b[0m     current \u001b[38;5;241m=\u001b[39m node_id2\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[20], line 93\u001b[0m, in \u001b[0;36mICDTree.get_root_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_root_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the root nodes of the tree.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [node \u001b[38;5;28;01mfor\u001b[39;00m node, degree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39min_degree() \u001b[38;5;28;01mif\u001b[39;00m degree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[20], line 93\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_root_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the root nodes of the tree.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [node \u001b[38;5;28;01mfor\u001b[39;00m node, degree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39min_degree() \u001b[38;5;28;01mif\u001b[39;00m degree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/networkx/classes/reportviews.py:580\u001b[0m, in \u001b[0;36mInDegreeView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes:\n\u001b[1;32m    579\u001b[0m         preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pred[n]\n\u001b[0;32m--> 580\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (n, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probe3 = TwoWordPSDProbe(random_BERT_dict[\"A000\"].shape[0], 64)\n",
    "\n",
    "loss3 = L1DistanceLoss()\n",
    "\n",
    "probe_regimen3 = ProbeRegimen(icd_tree)\n",
    "\n",
    "probe_regimen3.train(probe3, loss3, icd_codes_train, icd_codes_dev, random_BERT_dict, batch_size=10, name=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing TwoWordPSDProbe for a single large tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[predicting batches]: 100%|██████████| 327/327 [00:45<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.2709406532230638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probe_loaded3 = TwoWordPSDProbe(random_BERT_dict[\"A000\"].shape[0], 64)  # Replace ProbeModel with your actual model class\n",
    "probe_loaded3.load_state_dict(torch.load('saved_models/random_batch_size_10_epoch_6.pt'))\n",
    "probe_loaded3.eval()  # Set the model to evaluation mode\n",
    "\n",
    "probe_regimen3 = ProbeRegimen(icd_tree)\n",
    "\n",
    "# Generate predictions\n",
    "predictions3, labels3 = probe_regimen3.predict(probe_loaded3, icd_codes_test, random_BERT_dict, batch_size=10)\n",
    "\n",
    "correlations3, mean_correlations3 = calculate_spearman_correlations(predictions3, labels3)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating batches: 100%|██████████| 327/327 [00:47<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Spearman correlation: 0.296835555182813\n"
     ]
    }
   ],
   "source": [
    "mean_correlations = evaluate_full_correlations(icd_tree, random_BERT_dict, icd_codes_test, batch_size=10, shuffle_icd=False)\n",
    "print(f\"Mean Spearman correlation: {mean_correlations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
